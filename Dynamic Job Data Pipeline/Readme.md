# ğŸ“ŠIreland Job Market Analytics Pipeline

This repository documents a comprehensive **ELT (Extract, Load, Transform)** pipeline for collecting, managing, and analyzing **job posting data** from various sources. The project showcases a fully automated and scalable data workflow that utilizes **Google BigQuery**, **dbt**, **Airflow**, and **Looker** for end-to-end data management and visualization.

---

## ğŸ“š Table of Contents

- [ğŸš€ Project Overview](#-project-overview)
- [ğŸ—„ï¸ Data Sources](#ï¸-data-sources)
- [âš™ï¸ Environment Setup](#ï¸-environment-setup)
- [ğŸ”„ ELT Process](#-elt-process)
- [ğŸ’¾ Data Warehouse & Transformation](#-data-warehouse--transformation)
- [ğŸ“ˆ Data Visualization](#-data-visualization)
- [â° Automation with Airflow](#-automation-with-airflow)
- [ğŸ¯ Goals & Outcomes](#-goals--outcomes)
- [ğŸ’¡ Tech Stack](#-tech-stack)
- [ğŸ“„ License](#-license)

---

## ğŸš€ Project Overview

The primary objective of this project is to design and implement a **cloud-based, fully automated ELT pipeline** for processing and analyzing job postings data. The pipeline extracts data from **APIs** and **static datasets**, loads it into **BigQuery**, transforms it using **dbt**, and visualizes insights using **Looker**.

**âœ¨ Key Features:**
- **Real-time & Historical Job Data Extraction**
- **Automated ELT Pipeline using Airflow**
- **Cloud-based Data Storage & Transformation (BigQuery, dbt)**
- **Interactive Dashboards (Looker)**

---

## ğŸ—„ï¸ Data Sources

The ELT pipeline integrates data from the following sources:

### ğŸ“¡ **APIs:**
- **The Muse API** â€” Real-time job postings  
  - API Endpoint: `GET https://www.themuse.com/api/public/jobs`

### ğŸ“ **Static Datasets:**
- **Job Data Feeds** â€” Historical job postings since 2020  
  - Dataset: [Job Data Overview](https://jobdatafeeds.com/job-data-overview)  
  - Format: **JSON**

### ğŸ“Š **Data Collected:**
- Job Titles
- Company Details
- Location
- Job Descriptions
- Posting Dates
- Historical Job Trends

---

## âš™ï¸ Environment Setup

The environment was designed for scalability, automation, and data integrity.

1. **Google Cloud Platform (GCP)** â€” Hosted BigQuery and storage buckets.
2. **dbt** â€” Managed SQL-based data transformations in BigQuery.
3. **Airflow** â€” Automated data extraction, loading, and transformation jobs.
4. **Looker** â€” Used for data visualization and dashboarding.

---

## ğŸ”„ ELT Process

The **Extract, Load, Transform (ELT)** pipeline consists of the following stages:

### ğŸŸ¢ **1. Extract:**
- Data pulled from **The Muse API** and **static datasets**.
- Both real-time and historical job data collected.

### ğŸŸ¡ **2. Load:**
- Raw data loaded into **Google Cloud Storage (GCS)** buckets.
- Data moved into **BigQuery** as a central repository.

### ğŸ”µ **3. Transform:**
- **dbt** used for data cleaning, standardization, and schema structuring:
  - **Datatype Conversion**
  - **Null Value Imputation**
  - **Unnesting of Array Fields**
  - **Incremental Data Filtering** for daily updates
  - **Union of Multiple Sources** for historical data

---

## ğŸ’¾ Data Warehouse & Transformation

### **ğŸ”· Google BigQuery:**
- Chosen for its **scalability**, **high-performance querying**, and **cost-efficiency**.
- Integration with GCP services allows seamless data flow.

### **ğŸŸ¡ dbt (Data Build Tool):**
- Modular and reusable SQL-based transformations.
- Supports **version control** using Git.
- Built-in **testing** and **data validation** features.
- Simplifies the transformation logic while leveraging BigQuery's compute power.

---

## ğŸ“ˆ Data Visualization

**Looker** was used for creating interactive dashboards and reports to visualize job market trends.

### ğŸ“Š **Dashboards Include:**
- **Top Job Sectors** by location
- **Hiring Trends** over time
- **Salary Analysis** across industries
- **Popular Skills** required by employers

---

## â° Automation with Airflow

**Apache Airflow** was utilized to orchestrate the ELT pipeline.

### ğŸ”„ **Airflow Jobs:**
- **Daily Job Posting Pipeline:**  
  - Incremental extraction of new job postings.
  - Data stored in a **Daily Job Posting** dataset.

- **Historic Job Posting Pipeline:**  
  - Full data extraction for historical analysis.
  - Data stored in a **Historic Job Posting** dataset.

### âš¡ **Airflow Features Implemented:**
- **Task Scheduling** â€” Automated daily and historic data runs.
- **Error Handling** â€” Built-in error detection and retry mechanisms.
- **Scalable Workflows** â€” DAGs optimized for scalability and performance.

---

## ğŸ¯ Goals & Outcomes

### ğŸ¯ **Goals:**
- Build a **fully automated** data pipeline.
- Implement **scalable data transformations** using cloud resources.
- Create **accessible data insights** for end-users.
- Develop a **reusable ELT pipeline** for similar data projects.

### ğŸ† **Outcomes:**
- Achieved a **cloud-based, automated ELT pipeline**.
- Enhanced **data accessibility** through Looker dashboards.
- Optimized data transformations using **dbt** and **BigQuery**.
- Built a **robust orchestration system** using Airflow.

---

## ğŸ’¡ Tech Stack

| ğŸ—ï¸ **Tool/Framework** | ğŸ’¡ **Purpose**                     |
|-----------------------|-----------------------------------|
| **Google BigQuery**    | Data warehousing & storage       |
| **dbt**                | Data transformation (SQL-based)  |
| **Apache Airflow**     | Workflow orchestration           |
| **Looker**             | Data visualization & reporting   |
| **Google Cloud Storage** | Raw data storage               |
| **Python**             | Data extraction scripts          |
| **APIs & Static Datasets** | Data sources                  |

---

## ğŸ“„ License

This project is licensed under the **MIT License** â€” feel free to use, modify, and distribute it.

---

### ğŸš€ **Happy Data Engineering!**
